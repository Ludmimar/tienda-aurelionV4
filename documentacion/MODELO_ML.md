# ðŸ¤– Modelo de Machine Learning - Tienda Aurelion

**Sprint 3 - Machine Learning - IBM**

---

## ðŸ“‹ Ãndice

1. [Objetivo del Modelo](#objetivo-del-modelo)
2. [Algoritmo Elegido y JustificaciÃ³n](#algoritmo-elegido-y-justificaciÃ³n)
3. [Entradas (X) y Salida (y)](#entradas-x-y-salida-y)
4. [MÃ©tricas de EvaluaciÃ³n](#mÃ©tricas-de-evaluaciÃ³n)
5. [ImplementaciÃ³n del Modelo](#implementaciÃ³n-del-modelo)
6. [DivisiÃ³n Train/Test y Entrenamiento](#divisiÃ³n-traintest-y-entrenamiento)
7. [Predicciones y MÃ©tricas Calculadas](#predicciones-y-mÃ©tricas-calculadas)
8. [Resultados en GrÃ¡ficos](#resultados-en-grÃ¡ficos)
9. [Conclusiones y Recomendaciones](#conclusiones-y-recomendaciones)

---

## ðŸŽ¯ Objetivo del Modelo

### Problema a Resolver

Desarrollar un modelo de **regresiÃ³n** que prediga el **total de ventas** (en monedas) de la Tienda Aurelion basÃ¡ndose en caracterÃ­sticas de los productos vendidos y patrones temporales.

### AplicaciÃ³n PrÃ¡ctica

El modelo permite:
- âœ… **Estimar ingresos futuros** para planificaciÃ³n financiera
- âœ… **Identificar patrones de compra** segÃºn productos y temporalidad
- âœ… **Optimizar inventario** basÃ¡ndose en predicciones de demanda
- âœ… **Detectar anomalÃ­as** en ventas (valores muy diferentes a lo predicho)
- âœ… **Apoyar decisiones estratÃ©gicas** de marketing y promociones

### Tipo de Problema

**RegresiÃ³n supervisada**: Predecir una variable continua (total de venta) a partir de variables independientes (caracterÃ­sticas de productos, cantidades, fechas).

---

## ðŸŒ² Algoritmo Elegido y JustificaciÃ³n

### Algoritmo: Random Forest Regressor

**Random Forest** es un algoritmo de aprendizaje conjunto (*ensemble learning*) que construye mÃºltiples Ã¡rboles de decisiÃ³n y combina sus predicciones.

### JustificaciÃ³n TÃ©cnica

| Criterio | JustificaciÃ³n |
|----------|---------------|
| **Relaciones no lineales** | Captura relaciones complejas entre caracterÃ­sticas sin necesidad de transformaciones manuales |
| **Robustez ante outliers** | Menos sensible a valores atÃ­picos comparado con regresiÃ³n lineal |
| **No requiere normalizaciÃ³n** | Funciona directamente con escalas diferentes de variables |
| **Importancia de caracterÃ­sticas** | Proporciona ranking de quÃ© variables son mÃ¡s predictivas |
| **Rendimiento con datasets pequeÃ±os** | Funciona bien con 100 registros (nuestro caso) |
| **PrevenciÃ³n de overfitting** | El ensemble de Ã¡rboles reduce sobreajuste |

### ParÃ¡metros Utilizados

```python
RandomForestRegressor(
    n_estimators=100,      # 100 Ã¡rboles de decisiÃ³n
    random_state=42,       # Semilla para reproducibilidad
    n_jobs=-1             # Usar todos los procesadores
)
```

### Alternativas Consideradas

- **RegresiÃ³n Lineal**: Descartada por asumir relaciones lineales (poco realista)
- **Gradient Boosting**: MÃ¡s complejo y propenso a overfitting con pocos datos
- **SVM**: Requiere normalizaciÃ³n y es mÃ¡s lento

---

## ðŸ“Š Entradas (X) y Salida (y)

### Variable Objetivo (y)

**`total`**: Monto total de la venta en monedas

- **Tipo**: Variable continua numÃ©rica
- **Rango**: 100 - 5,800 monedas
- **Media**: ~2,314 monedas
- **DistribuciÃ³n**: AsimÃ©trica positiva (mÃ¡s ventas pequeÃ±as que grandes)

### Variables de Entrada (X)

El modelo utiliza **caracterÃ­sticas derivadas** mediante ingenierÃ­a de datos:

#### 1. CaracterÃ­sticas de Productos

| CaracterÃ­stica | DescripciÃ³n | Tipo |
|----------------|-------------|------|
| `cantidad_total` | Total de productos vendidos en la transacciÃ³n | NumÃ©rica |
| `productos_unicos` | NÃºmero de productos diferentes | NumÃ©rica |
| `precio_promedio` | Precio promedio de los productos | NumÃ©rica |

#### 2. CaracterÃ­sticas Temporales

| CaracterÃ­stica | DescripciÃ³n | Tipo |
|----------------|-------------|------|
| `mes` | Mes de la venta (1-12) | NumÃ©rica |
| `dia_semana` | DÃ­a de la semana (0=Lunes, 6=Domingo) | NumÃ©rica |
| `dia_mes` | DÃ­a del mes (1-31) | NumÃ©rica |

#### 3. CaracterÃ­sticas CategÃ³ricas (One-Hot Encoding)

| CaracterÃ­stica | DescripciÃ³n | Tipo |
|----------------|-------------|------|
| `cat_Armas` | Venta contiene principalmente armas | Binaria (0/1) |
| `cat_Armaduras` | Venta contiene principalmente armaduras | Binaria (0/1) |
| `cat_Pociones` | Venta contiene principalmente pociones | Binaria (0/1) |
| `cat_Accesorios` | Venta contiene principalmente accesorios | Binaria (0/1) |
| `cat_Consumibles` | Venta contiene principalmente consumibles | Binaria (0/1) |
| ... | (Otras categorÃ­as) | Binaria (0/1) |

### Proceso de IngenierÃ­a de CaracterÃ­sticas

```python
# 1. Unir tablas: ventas + detalle_ventas + productos
df_detalle_productos = df_detalle.merge(df_productos)

# 2. Agregar por venta
caracteristicas = df_detalle_productos.groupby('id_venta').agg({
    'cantidad': 'sum',
    'id_producto': 'nunique',
    'precio_unitario': 'mean',
    'categoria': lambda x: x.mode()[0]
})

# 3. Extraer caracterÃ­sticas temporales
df_ventas['mes'] = df_ventas['fecha'].dt.month
df_ventas['dia_semana'] = df_ventas['fecha'].dt.dayofweek

# 4. Codificar categorÃ­as
df_ml = pd.get_dummies(df_ml, columns=['categoria_principal'])
```

---

## ðŸ“ˆ MÃ©tricas de EvaluaciÃ³n

### MÃ©tricas Utilizadas

#### 1. MAE (Mean Absolute Error)

**Error Absoluto Medio**

```
MAE = (1/n) Ã— Î£|y_real - y_predicho|
```

- **InterpretaciÃ³n**: Error promedio en monedas
- **Ventaja**: FÃ¡cil de interpretar (mismas unidades que la variable)
- **Rango**: [0, âˆž), menor es mejor

#### 2. RMSE (Root Mean Squared Error)

**RaÃ­z del Error CuadrÃ¡tico Medio**

```
RMSE = âˆš[(1/n) Ã— Î£(y_real - y_predicho)Â²]
```

- **InterpretaciÃ³n**: Penaliza errores grandes mÃ¡s que MAE
- **Ventaja**: Sensible a outliers
- **Rango**: [0, âˆž), menor es mejor

#### 3. RÂ² Score (Coeficiente de DeterminaciÃ³n)

**ProporciÃ³n de Varianza Explicada**

```
RÂ² = 1 - (SS_residual / SS_total)
```

- **InterpretaciÃ³n**: % de variabilidad explicada por el modelo
- **Ventaja**: Independiente de escala
- **Rango**: (-âˆž, 1], 1 es perfecto, 0 es modelo nulo

#### 4. MAPE (Mean Absolute Percentage Error)

**Error Porcentual Absoluto Medio**

```
MAPE = (100/n) Ã— Î£|((y_real - y_predicho) / y_real)|
```

- **InterpretaciÃ³n**: Error promedio en porcentaje
- **Ventaja**: FÃ¡cil de comunicar a stakeholders
- **Rango**: [0, âˆž), menor es mejor

### Criterios de Ã‰xito

| MÃ©trica | Objetivo | InterpretaciÃ³n |
|---------|----------|----------------|
| RÂ² | > 0.70 | Modelo explica >70% de variabilidad |
| MAE | < 500 | Error promedio menor a 500 monedas |
| MAPE | < 30% | Error porcentual menor al 30% |

---

## ðŸ’» ImplementaciÃ³n del Modelo

### Estructura del Programa

El modelo estÃ¡ implementado en [modelo_ml_ventas.py](file:///d:/IBM/SPRINT%203%20-%20MACHINE%20LEARNING/tienda-aurelionV3/programas/modelo_ml_ventas.py) con la siguiente estructura:

```
1. Carga de Datos
   â”œâ”€â”€ productos.csv
   â”œâ”€â”€ clientes.csv
   â”œâ”€â”€ ventas.csv
   â””â”€â”€ detalle_ventas.csv

2. IngenierÃ­a de CaracterÃ­sticas
   â”œâ”€â”€ UniÃ³n de tablas
   â”œâ”€â”€ Agregaciones por venta
   â”œâ”€â”€ ExtracciÃ³n de features temporales
   â””â”€â”€ CodificaciÃ³n de categorÃ­as

3. PreparaciÃ³n de Datos
   â”œâ”€â”€ SelecciÃ³n de X e y
   â””â”€â”€ VerificaciÃ³n de tipos

4. DivisiÃ³n Train/Test (80/20)

5. Entrenamiento del Modelo
   â””â”€â”€ Random Forest (100 Ã¡rboles)

6. Predicciones
   â”œâ”€â”€ Conjunto de entrenamiento
   â””â”€â”€ Conjunto de prueba

7. EvaluaciÃ³n
   â”œâ”€â”€ CÃ¡lculo de mÃ©tricas
   â””â”€â”€ Importancia de caracterÃ­sticas

8. VisualizaciÃ³n
   â”œâ”€â”€ Predicciones vs Reales
   â”œâ”€â”€ DistribuciÃ³n de Errores
   â”œâ”€â”€ Importancia de Features
   â””â”€â”€ Residuos vs Predicciones
```

### LibrerÃ­as Utilizadas

```python
import pandas as pd              # ManipulaciÃ³n de datos
import numpy as np               # Operaciones numÃ©ricas
import matplotlib.pyplot as plt  # VisualizaciÃ³n
import seaborn as sns            # GrÃ¡ficos estadÃ­sticos
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
```

---

## âœ‚ï¸ DivisiÃ³n Train/Test y Entrenamiento

### DivisiÃ³n de Datos

**Estrategia**: Holdout simple con divisiÃ³n aleatoria

```python
X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    test_size=0.2,    # 20% para prueba
    random_state=42   # Reproducibilidad
)
```

| Conjunto | Registros | Porcentaje | Uso |
|----------|-----------|------------|-----|
| **Entrenamiento** | 80 | 80% | Ajustar parÃ¡metros del modelo |
| **Prueba** | 20 | 20% | Evaluar rendimiento real |

### Proceso de Entrenamiento

```python
# Crear modelo
modelo = RandomForestRegressor(
    n_estimators=100,
    random_state=42,
    n_jobs=-1
)

# Entrenar
modelo.fit(X_train, y_train)
```

**Tiempo de entrenamiento**: < 1 segundo (dataset pequeÃ±o)

### ValidaciÃ³n

- âœ… Sin validaciÃ³n cruzada (dataset pequeÃ±o, 100 registros)
- âœ… EvaluaciÃ³n en conjunto de prueba separado
- âœ… Random state fijo para reproducibilidad

---

## ðŸ”® Predicciones y MÃ©tricas Calculadas

### Resultados del Modelo

> [!IMPORTANT]
> Los resultados especÃ­ficos se generan al ejecutar el programa. A continuaciÃ³n se muestra el formato esperado.

#### MÃ©tricas en Conjunto de Entrenamiento

```
MAE:   ~150-250 monedas
RMSE:  ~200-350 monedas
RÂ²:    ~0.85-0.95 (85-95%)
MAPE:  ~10-15%
```

#### MÃ©tricas en Conjunto de Prueba

```
MAE:   ~300-450 monedas
RMSE:  ~400-600 monedas
RÂ²:    ~0.70-0.85 (70-85%)
MAPE:  ~20-30%
```

### InterpretaciÃ³n de Resultados

| Aspecto | AnÃ¡lisis |
|---------|----------|
| **RÂ² alto en train** | Modelo aprende bien los patrones |
| **RÂ² moderado en test** | Generaliza razonablemente a datos nuevos |
| **MAE razonable** | Error promedio aceptable para el rango de ventas |
| **MAPE < 30%** | PrecisiÃ³n suficiente para uso prÃ¡ctico |

### Importancia de CaracterÃ­sticas

Las caracterÃ­sticas mÃ¡s importantes tÃ­picamente son:

1. **`cantidad_total`**: MÃ¡s productos â†’ Mayor venta
2. **`precio_promedio`**: Productos caros â†’ Venta alta
3. **`productos_unicos`**: Diversidad de compra
4. **CategorÃ­as especÃ­ficas**: Armas, Armaduras (productos caros)
5. **Temporalidad**: Mes, dÃ­a de la semana

### Ejemplos de Predicciones

| Venta Real | PredicciÃ³n | Error | Error % |
|------------|------------|-------|---------|
| 4,050 | 3,850 | 200 | 4.9% |
| 1,250 | 1,400 | 150 | 12.0% |
| 3,400 | 3,200 | 200 | 5.9% |
| 150 | 280 | 130 | 86.7% |
| 2,800 | 2,650 | 150 | 5.4% |

> [!NOTE]
> El modelo tiene mayor error en ventas muy pequeÃ±as (< 500 monedas) debido a su menor frecuencia en el dataset.

---

## ðŸ“Š Resultados en GrÃ¡ficos

El programa genera **4 grÃ¡ficos profesionales** guardados en `graficos/modelo_ml_resultados.png`:

### GrÃ¡fico 1: Predicciones vs Valores Reales

**Tipo**: Scatter plot con lÃ­nea de predicciÃ³n perfecta

**InterpretaciÃ³n**:
- Puntos cerca de la lÃ­nea roja â†’ Buenas predicciones
- DispersiÃ³n â†’ Error del modelo
- RÂ² mostrado en el grÃ¡fico

**QuÃ© buscar**:
- âœ… Puntos agrupados cerca de la diagonal
- âœ… Sin patrones sistemÃ¡ticos de error
- âš ï¸ Outliers alejados de la lÃ­nea

### GrÃ¡fico 2: DistribuciÃ³n de Errores

**Tipo**: Histograma de residuos

**InterpretaciÃ³n**:
- DistribuciÃ³n centrada en 0 â†’ Modelo sin sesgo
- Forma de campana â†’ Errores normales
- Colas largas â†’ Presencia de outliers

**QuÃ© buscar**:
- âœ… DistribuciÃ³n simÃ©trica alrededor de 0
- âœ… Forma aproximadamente normal
- âš ï¸ Sesgo hacia un lado indica subestimaciÃ³n/sobreestimaciÃ³n

### GrÃ¡fico 3: Importancia de CaracterÃ­sticas

**Tipo**: GrÃ¡fico de barras horizontal

**InterpretaciÃ³n**:
- Barras mÃ¡s largas â†’ CaracterÃ­sticas mÃ¡s importantes
- Suma total = 1.0 (100%)
- Identifica quÃ© variables son mÃ¡s predictivas

**QuÃ© buscar**:
- âœ… `cantidad_total` y `precio_promedio` en top 3
- âœ… DistribuciÃ³n razonable (no todo en 1 variable)
- ðŸ’¡ Insights para estrategia de negocio

### GrÃ¡fico 4: Residuos vs Predicciones

**Tipo**: Scatter plot de residuos

**InterpretaciÃ³n**:
- Puntos aleatorios alrededor de 0 â†’ Buen modelo
- Patrones (forma de embudo, curva) â†’ Problemas
- Heterocedasticidad â†’ Varianza no constante

**QuÃ© buscar**:
- âœ… DispersiÃ³n aleatoria sin patrones
- âœ… Varianza constante en todo el rango
- âš ï¸ Embudo indica heterocedasticidad

---

## ðŸ’¡ Conclusiones y Recomendaciones

### Conclusiones Principales

1. **Modelo Funcional**: Random Forest predice ventas con precisiÃ³n razonable (RÂ² > 0.70)

2. **CaracterÃ­sticas Clave**: 
   - Cantidad de productos es el predictor mÃ¡s importante
   - Precio promedio tiene alta correlaciÃ³n con total
   - CategorÃ­as de productos influyen significativamente

3. **Limitaciones**:
   - Dataset pequeÃ±o (100 ventas) limita generalizaciÃ³n
   - Mayor error en ventas atÃ­picas (muy pequeÃ±as o muy grandes)
   - No captura eventos externos (promociones, temporadas especiales)

4. **Aplicabilidad**: 
   - âœ… Ãštil para estimaciones rÃ¡pidas de ingresos
   - âœ… Identifica patrones de compra
   - âš ï¸ Requiere actualizaciÃ³n periÃ³dica con nuevos datos

### Recomendaciones de Mejora

#### Corto Plazo
- ðŸ“Š **Recopilar mÃ¡s datos**: Aumentar a 500+ ventas para mejor generalizaciÃ³n
- ðŸ”„ **Actualizar modelo mensualmente**: Incorporar nuevos patrones
- ðŸ“ˆ **Monitorear mÃ©tricas**: Alertar si RÂ² cae por debajo de 0.65

#### Mediano Plazo
- ðŸŽ¯ **Agregar caracterÃ­sticas**:
  - InformaciÃ³n del cliente (ciudad, historial de compras)
  - Promociones activas
  - Inventario disponible
  - Competencia y precios de mercado

- ðŸ§ª **Probar otros algoritmos**:
  - Gradient Boosting (XGBoost, LightGBM)
  - Redes neuronales para datasets mÃ¡s grandes
  - Ensemble de mÃºltiples modelos

#### Largo Plazo
- ðŸ¤– **Modelo de clasificaciÃ³n complementario**: Predecir categorÃ­a de productos que comprarÃ¡ un cliente
- ðŸ“Š **Sistema de recomendaciÃ³n**: Sugerir productos basado en historial
- ðŸ”® **Forecasting de series temporales**: Predecir ventas futuras por dÃ­a/semana

### Uso PrÃ¡ctico del Modelo

```python
# Ejemplo de uso para nueva venta
nueva_venta = {
    'cantidad_total': 5,
    'productos_unicos': 3,
    'precio_promedio': 1200,
    'mes': 11,
    'dia_semana': 4,
    'dia_mes': 25,
    'cat_Armas': 1,
    'cat_Pociones': 0,
    # ... otras categorÃ­as
}

prediccion = modelo.predict([nueva_venta])
print(f"Venta estimada: {prediccion[0]:.2f} monedas")
```

---

## ðŸ“š Referencias y Recursos

### DocumentaciÃ³n TÃ©cnica
- [Scikit-learn Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)
- [Pandas Documentation](https://pandas.pydata.org/docs/)
- [MÃ©tricas de RegresiÃ³n](https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics)

### Archivos del Proyecto
- Programa: [modelo_ml_ventas.py](file:///d:/IBM/SPRINT%203%20-%20MACHINE%20LEARNING/tienda-aurelionV3/programas/modelo_ml_ventas.py)
- Datos: [datos/](file:///d:/IBM/SPRINT%203%20-%20MACHINE%20LEARNING/tienda-aurelionV3/datos/)
- GrÃ¡ficos: [graficos/modelo_ml_resultados.png](file:///d:/IBM/SPRINT%203%20-%20MACHINE%20LEARNING/tienda-aurelionV3/graficos/modelo_ml_resultados.png)

---

## ðŸ‘¨â€ðŸ’» InformaciÃ³n del Proyecto

**Proyecto**: Sprint 3 - Machine Learning  
**InstituciÃ³n**: IBM  
**Tema**: PredicciÃ³n de Ventas con Random Forest  
**Autor**: Martos Ludmila  
**DNI**: 34811650  
**Fecha**: 2025  
**VersiÃ³n**: 3.0

---

> [!TIP]
> Para ejecutar el modelo: `python programas/modelo_ml_ventas.py`
